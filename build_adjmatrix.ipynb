{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from groq import Groq\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
    "groq_api_key=os.environ['GROQ_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are trying to match different job titles of various professionals with the following domains: \n",
    "1. Software\n",
    "2. Data Scientist\n",
    "3. Consultant\n",
    "4. Management\n",
    "5. Product Engineering\n",
    "6. Academia\n",
    "7. Finance\n",
    "8. Law\n",
    "9. Sales & Marketing\n",
    "10. Mechatronics\n",
    "\n",
    "The job title must be matched with the corresponding domain it is included in, so that professionals of each domain can be grouped together. The given titles will bein a list form and the groupings must be presented in a list form as well.\n",
    "\n",
    "Here are a few examples:\n",
    "1. Software: Oracle | IBM Research; Software Developer @ Times Internet; Full Stack Developer; SDE-1 @ Amazon\n",
    "2. Data Science: Senior Data Scientist @ American Express; Data Science @Amex\n",
    "3. Consultant: Training Consultant; Associate, Client Services at AlphaSights; Risk Consultant; Human Capital Consultant \n",
    "4. Management: Backing India's next generation brands; BIU-Business Analyst at Axis Bank; Hiring React/Flutter Developers\n",
    "5. Product Engineering: Product@AzaFashions; Product @ Liquiloans; APM at MasterCard; \n",
    "6. Academia: IIM Calcutta PGP '25; Chemical Engineering | Indian Institute of Technology, Kharagpur; Werkstudent: Deutz AG\n",
    "7. Finance: CA || MBA(FMS); Deutsche Bank; Capital Markets - Blackstone Real Estate\n",
    "8. Law: Legal Operations & Technology | In-House | Lawyer\n",
    "9. Sales & Marketing: Insights Manager; Fabric Manufacturer and Exporter\n",
    "10. Mechatronics: Incoming @ JLR India\n",
    "As you can see, each job title is separated by a semi colon for clarity. I will be providing a list of job titles, and you are supposed to classify them in a similar fashion in the 10 listed domains. \n",
    "\n",
    "You should understand what work the person with the specific job title would be doing, and which domain it would fall into, with the help of the given example. If a proper title is not available, you can consider how the work in the company/other details specified would be.\n",
    "Provide only a single domain name (e.g., Software, Data Science, etc.) that the job title suits maximum to without any explanations. If there are multiple matching domains, choose any one.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define a function to categorize job titles\n",
    "def categorize_job_title(job_title):\n",
    "    llm = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": prompt_template\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": job_title\n",
    "            }\n",
    "        ],\n",
    "        model=\"mixtral-8x7b-32768\",\n",
    "    )\n",
    "    return (llm.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Scientist\n"
     ]
    }
   ],
   "source": [
    "#prompt = PromptTemplate(input_variables=[\"job_title\"], template=prompt_template).format(job_title=\"Manager\")\n",
    "llm = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": prompt_template\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Data Science @Amex\"\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    ")\n",
    "\n",
    "print(llm.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_files(folder_path):\n",
    "    user_data = {}\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".json\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            with open(file_path, \"r\") as file:\n",
    "                data = json.load(file)\n",
    "                user_id = os.path.splitext(file_name)[0]\n",
    "                job_title = data.get(\"position\", \"\")\n",
    "                if job_title:\n",
    "                    domain = categorize_job_title(job_title)\n",
    "                    user_data[user_id] = {\"job_title\": job_title.split('|')[0].strip().split('\\n')[0].strip() if job_title else \"No idea\", \"domain\": domain}\n",
    "    return user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adjacency_matrix(user_data):\n",
    "    user_ids = list(user_data.keys())\n",
    "    n = len(user_ids)\n",
    "    matrix = np.zeros((n, n), dtype=int)\n",
    "    domains = [user_data[user_id][\"domain\"] for user_id in user_ids]\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if domains[i] == domains[j]:\n",
    "                matrix[i][j] = 1\n",
    "    return pd.DataFrame(matrix, index=user_ids, columns=user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def process_json_files(json_folder, output_user_data, output_adjacency_matrix):\n",
    "    user_data = {}\n",
    "    adjacency_matrix = None\n",
    "\n",
    "    try:\n",
    "        # Load existing data if files exist\n",
    "        if os.path.exists(output_user_data):\n",
    "            with open(output_user_data, \"r\") as file:\n",
    "                user_data = json.load(file)\n",
    "\n",
    "        if os.path.exists(output_adjacency_matrix):\n",
    "            adjacency_matrix = pd.read_csv(output_adjacency_matrix, index_col=0)\n",
    "        else:\n",
    "            adjacency_matrix = pd.DataFrame()\n",
    "\n",
    "        user_files = os.listdir(json_folder)\n",
    "        for file_name in tqdm(user_files, desc=\"Processing JSON files\"):\n",
    "            user_id = os.path.splitext(file_name)[0]\n",
    "            if user_id in user_data:\n",
    "                continue  # Skip already processed users\n",
    "\n",
    "            file_path = os.path.join(json_folder, file_name)\n",
    "            with open(file_path, \"r\") as file:\n",
    "                user_details = json.load(file)\n",
    "\n",
    "            # Extract job title and classify domain\n",
    "            job_title = user_details.get(\"position\", \"Unknown Position\")\n",
    "            domain = categorize_job_title(job_title.split('|')[0].strip().split('\\n')[0].strip() if job_title else \"Unknown Position\")\n",
    "\n",
    "            if not domain:\n",
    "                print(f\"Skipping user {user_id}: domain could not be classified.\")\n",
    "                continue\n",
    "\n",
    "            # Save user data with domain\n",
    "            user_data[user_id] = {\n",
    "                \"details\": user_details,\n",
    "                \"domain\": domain,\n",
    "            }\n",
    "\n",
    "            # Update adjacency matrix\n",
    "            try:\n",
    "                new_row = pd.DataFrame(\n",
    "                    0, index=[user_id], columns=adjacency_matrix.index\n",
    "                )\n",
    "                new_column = pd.DataFrame(\n",
    "                    0, index=adjacency_matrix.index, columns=[user_id]\n",
    "                )\n",
    "\n",
    "                for existing_user_id in adjacency_matrix.index:\n",
    "                    if (\n",
    "                        existing_user_id in user_data\n",
    "                        and domain == user_data[existing_user_id][\"domain\"]\n",
    "                    ):\n",
    "                        new_row.loc[user_id, existing_user_id] = 1\n",
    "                        new_column.loc[existing_user_id, user_id] = 1\n",
    "\n",
    "                adjacency_matrix = pd.concat([adjacency_matrix, new_row], axis=0)\n",
    "                adjacency_matrix = pd.concat([adjacency_matrix, new_column], axis=1)\n",
    "                adjacency_matrix.fillna(0, inplace=True)\n",
    "\n",
    "                # Save progress after processing each user\n",
    "                with open(output_user_data, \"w\") as file:\n",
    "                    json.dump(user_data, file)\n",
    "\n",
    "                adjacency_matrix.to_csv(output_adjacency_matrix)\n",
    "            except KeyError as e:\n",
    "                print(f\"Error updating adjacency matrix for user {user_id}: {e}\")\n",
    "                continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(\"Saving progress...\")\n",
    "        # Save current user data\n",
    "        with open(output_user_data, \"w\") as file:\n",
    "            json.dump(user_data, file)\n",
    "\n",
    "        # Save adjacency matrix if partially created\n",
    "        if adjacency_matrix is not None:\n",
    "            adjacency_matrix.to_csv(output_adjacency_matrix)\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSON files:  65%|██████▌   | 2200/3370 [44:58<2:13:01,  6.82s/it]"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    json_folder = \"final_user_profiles\"  # Replace with your JSON folder path\n",
    "    output_user_data = \"user_data.json\"\n",
    "    output_adjacency_matrix = \"adjacency_matrix.csv\"\n",
    "\n",
    "    process_json_files(json_folder, output_user_data, output_adjacency_matrix)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
