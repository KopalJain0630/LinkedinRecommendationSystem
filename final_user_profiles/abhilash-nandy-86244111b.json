{
    "city": "Midnapore Sadar, India",
    "position": "Prime Minister's Research Fellow; Microsoft Research India PhD Awardee 2024; Project Intern at Leibniz Universität Hannover; Pursuing PhD in CSE at Indian Institute of Technology, Kharagpur",
    "experience": [
        {
            "title": "Indian Institute of Technology, Kharagpur",
            "location": "Kharagpur, West Bengal, India",
            "description_html": null,
            "duration": "4 years 11 months",
            "positions": [
                {
                    "subtitle": "Indian Institute of Technology, Kharagpur",
                    "meta": "Sep 2020 - Present 4 years 4 months",
                    "description": "Pursuing PhD in Natural Language Processing, specializing in Domain-Specific Pre-training and its applications.",
                    "duration": "Sep 2020 - Present 4 years 4 months",
                    "start_date": "Sep 2020",
                    "end_date": "Present",
                    "duration_short": "4 years 4 months",
                    "title": "PHD Student",
                    "description_html": "Pursuing PhD in Natural Language Processing, specializing in Domain-Specific Pre-training and its applications. <!---->"
                },
                {
                    "subtitle": "Indian Institute of Technology, Kharagpur",
                    "meta": "Feb 2020 - Sep 2020 8 months",
                    "duration": "Feb 2020 Sep 2020 8 months",
                    "start_date": "Feb 2020",
                    "end_date": "Sep 2020",
                    "duration_short": "8 months",
                    "title": "Research Scientist",
                    "description_html": null
                }
            ],
            "company": "Indian Institute of Technology, Kharagpur",
            "url": "",
            "company_logo_url": null
        },
        {
            "title": "Research Internship",
            "location": "Bengaluru, Karnataka, India",
            "description": "I worked as a research intern in the area of Multi-Document Summarization",
            "description_html": "I worked as a research intern in the area of Multi-Document Summarization <!---->",
            "duration": "May 2024 Aug 2024 4 months",
            "start_date": "May 2024",
            "end_date": "Aug 2024",
            "duration_short": "4 months",
            "company": "Adobe",
            "company_id": "adobe",
            "url": "",
            "company_logo_url": ""
        },
        {
            "title": "Research Intern",
            "location": "Hannover, Lower Saxony, Germany",
            "description": "Working on NLP applications on User E-Manuals and Procedural Text",
            "description_html": "Working on NLP applications on User E-Manuals and Procedural Text <!---->",
            "duration": "Aug 2021 Dec 2022 1 year 5 months",
            "start_date": "Aug 2021",
            "end_date": "Dec 2022",
            "duration_short": "1 year 5 months",
            "company": "Leibniz Universität Hannover",
            "url": "",
            "company_logo_url": ""
        },
        {
            "title": "IEEE Member",
            "description_html": null,
            "duration": "Apr 2018 Sep 2020 2 years 6 months",
            "start_date": "Apr 2018",
            "end_date": "Sep 2020",
            "duration_short": "2 years 6 months",
            "company": "IEEE",
            "company_id": "ieee",
            "url": "",
            "company_logo_url": ""
        },
        {
            "title": "Software Developer",
            "location": "Noida Area, India",
            "description": "Software Development Engineer",
            "description_html": "Software Development Engineer <!---->",
            "duration": "Jun 2019 Dec 2019 7 months",
            "start_date": "Jun 2019",
            "end_date": "Dec 2019",
            "duration_short": "7 months",
            "company": "Adobe",
            "company_id": "adobe",
            "url": "",
            "company_logo_url": ""
        },
        {
            "title": "Research Intern",
            "location": "Bengaluru Area, India",
            "description": "Worked on cutting-edge NLP research in the Big Data Experience Labs, Adobe, Bengaluru. The internship resulted in a research paper as well, with the link below.",
            "description_html": "Worked on cutting-edge NLP research in the Big Data Experience Labs, Adobe, Bengaluru. The internship resulted in a research paper as well, with the link below. <!---->",
            "duration": "May 2018 Jul 2018 3 months",
            "start_date": "May 2018",
            "end_date": "Jul 2018",
            "duration_short": "3 months",
            "company": "Adobe",
            "company_logo_url": ""
        },
        {
            "title": "Research Intern",
            "location": "Noida Area, India",
            "description": "Predictive Risk Analysis",
            "description_html": "Predictive Risk Analysis <!---->",
            "duration": "Dec 2017 Jan 2018 2 months",
            "start_date": "Dec 2017",
            "end_date": "Jan 2018",
            "duration_short": "2 months",
            "company": "Tata Consultancy Services",
            "company_id": "tata-consultancy-services",
            "url": "",
            "company_logo_url": ""
        },
        {
            "title": "Research Intern",
            "location": "Kolkata Area, India",
            "description": "Research Internship on Deep Learning",
            "description_html": "Research Internship on Deep Learning <!---->",
            "duration": "May 2017 Jul 2017 3 months",
            "start_date": "May 2017",
            "end_date": "Jul 2017",
            "duration_short": "3 months",
            "company": "Indian Statistical Instiute, Kolkata",
            "company_logo_url": ""
        }
    ],
    "education": [
        {
            "title": "Indian Institute of Technology, Kharagpur",
            "degree": "Doctor of Philosophy - PhD",
            "field": "Computer Science",
            "url": "",
            "start_year": "2020",
            "end_year": "2025",
            "description": null,
            "description_html": null,
            "institute_logo_url": ""
        },
        {
            "title": "Indian Institute of Technology, Kharagpur",
            "degree": "Bachelor of Technology (B.Tech.)",
            "field": "Electronics and Electrical Communication Engineering",
            "url": "",
            "start_year": "2015",
            "end_year": "2019",
            "description": "Activities and Societies: Innovator at MNFIC. Part of the gold-winning hardware modelling team in the tech contingent of LBS Hall of Residence, IIT KGP, which won the General Championship (Tech) in 2017-18 session.",
            "description_html": "Activities and Societies: Innovator at MNFIC. Part of the gold-winning hardware modelling team in the tech contingent of LBS Hall of Residence, IIT KGP, which won the General Championship (Tech) in 2017-18 session.",
            "institute_logo_url": ""
        },
        {
            "title": "Delhi Public School, Visakhapatnam",
            "degree": "10/10",
            "start_year": "2012",
            "end_year": "2013",
            "description": null,
            "description_html": null,
            "institute_logo_url": ""
        }
    ],
    "courses": null,
    "certifications": null,
    "current_company_name": "Indian Institute of Technology, Kharagpur",
    "publications": "[{\"title\":\"***FastDoc***: Domain-Specific Fast Continual Pre-training Technique using Document-Level Metadata and Taxonomy\",\"subtitle\":\"Transactions on Machine Learning Research\",\"date\":\"June 12, 2024\",\"description\":\"In this paper, we propose FastDoc (Fast Continual Pre-training Technique using Document Level Metadata and Taxonomy), a novel, compute-efficient framework that utilizes Document metadata and Domain-Specific Taxonomy as supervision signals to continually pre-train transformer encoder on a domain-specific corpus. The main innovation is that during domain-specific pretraining, an open-domain encoder is continually pre-trained using sentence-level embeddings as inputs (to accommodate long documents), however, fine-tuning is done with token-level embeddings as inputs to this encoder. We perform such domainspecific pre-training on three different domains namely customer support, scientific, and legal domains, and compare performance on 6 different downstream tasks and 9 different datasets. The novel use of document-level supervision along with sentence-level embedding input for pre-training reduces pre-training compute by around 1,000, 4,500, and 500 times compared to MLM and/or NSP in Customer Support, Scientific, and Legal Domains, respectively1. The reduced training time does not lead to a deterioration in performance. In fact we show that FastDoc either outperforms or performs on par with several competitive transformer-based baselines in terms of character-level F1 scores and other automated metrics in the Customer Support, Scientific, and Legal Domains. Moreover, reduced training aids in mitigating the risk of catastrophic forgetting. Thus, unlike baselines, FastDoc shows a negligible drop in performance on open domain.\"},{\"title\":\"Question Answering over Electronic Devices: A New Benchmark Dataset and a Multi-Task Learning based QA Framework\",\"date\":\"September 14, 2021\",\"description\":\"Answering questions asked from instructional corpora such as E-manuals, recipe books, etc., has been far less studied than open-domain factoid context-based question answering. This can be primarily attributed to the absence of standard benchmark datasets. In this paper we meticulously create a large amount of data connected with E-manuals and develop suitable algorithm to exploit it. We collect E-Manual Corpus, a huge corpus of 307,957 E-manuals and pretrain RoBERTa on this large corpus. We create various benchmark QA datasets which include question answer pairs curated by experts based upon two E-manuals, real user questions from Community Question Answering Forum pertaining to E-manuals etc. We introduce EMQAP (E-Manual Question Answering Pipeline)that answers questions pertaining to electronics devices. Built upon the pretrained RoBERTa, it harbors a supervised multi-task learning framework which efficiently performs the dual tasks of identifying the section in the E-manual where the answer can be found and the exact answer span within that section. For E-Manual annotated question-answer pairs, we show an improvement of about 40% in ROUGE-L F1 scores over the most competitive baseline. We perform a detailed ablation study and establish the versatility of EMQAP across different circumstances.\"},{\"title\":\"cs60075_team2 at SemEval-2021 Task 1: Lexical Complexity Prediction using Transformer-based Language Models pre-trained on various text corpora\",\"subtitle\":\"Association for Computational Linguistics\",\"date\":\"July 31, 2021\",\"description\":\"The main contribution of this paper is to fine-tune transformer-based language models pre-trained on several text corpora, some being general (E.g., Wikipedia, BooksCorpus), some being the corpora from which the CompLex Dataset was extracted, and others being from other specific domains such as Finance, Law, etc. We perform ablation studies on selecting the transformer models and how their individual complexity scores are aggregated to get the resulting complexity scores. Our method achieves a best Pearson Correlation of 0.784 in sub-task 1 (single word) and 0.836 in sub-task 2 (multiple word expressions).\"},{\"title\":\"indicnlp@ kgp at DravidianLangTech-EACL2021: Offensive Language Identification in Dravidian Languages\",\"subtitle\":\"Association for Computational Linguistics\",\"date\":\"April 18, 2021\",\"description\":\"The paper aims to classify different offensive content types in 3 code-mixed Dravidian language datasets. The work leverages existing state of the art approaches in text classification by incorporating additional data and transfer learning on pre-trained models. Our final submission is an ensemble of an AWD-LSTM based model along with 2 different transformer model architectures based on BERT and RoBERTa. We achieved weighted-average F1 scores of 0.97, 0.77, and 0.72 in the Malayalam-English, Tamil-English, and Kannada-English datasets ranking 1st, 2nd, and 3rd on the respective shared-task leaderboards.\"},{\"title\":\"A Survey on Applications of Siamese Neural Networks in Computer Vision\",\"subtitle\":\"IEEE\",\"date\":\"August 2, 2020\",\"description\":\"Computer Vision nowadays uses many Deep Learning techniques in order to make the computer learn data representations from images and image sequences (as in videos). One of the important tasks in this respect is learning the similarity between two given images, which can be readily accomplished by learning a similarity criterion between the images. This can be readily accomplished using Siamese Convolutional Neural Networks (Siamese CNNs). Siamese CNNs can learn a similarity criterion between various kinds of image pairs. The paper presents a survey, which deals with the study of some remarkable papers which have used Siamese CNNs and triplet nets (which are a variation of the Siamese CNNs) in order to learn how similar are two images to one another.\"},{\"title\":\"Identification of Cervical Pathology using Adversarial Neural Networks\",\"subtitle\":\"ArXiv\",\"date\":\"April 27, 2020\",\"description\":\"Various screening and diagnostic methods have led to a large reduction of cervical cancer death rates in developed countries. However, cervical cancer is the leading cause of cancer related deaths in women in India and other low and middle income countries (LMICs) especially among the urban poor and slum dwellers. Several sophisticated techniques such as cytology tests, HPV tests etc. have been widely used for screening of cervical cancer. These tests are inherently time consuming. In this paper, we propose a convolutional autoencoder based framework, having an architecture similar to SegNet which is trained in an adversarial fashion for classifying images of the cervix acquired using a colposcope. We validate performance on the Intel-Mobile ODT cervical image classification dataset. The proposed method outperforms the standard technique of fine-tuning convolutional neural networks pre-trained on ImageNet database with an average accuracy of 73.75%.\"},{\"title\":\"A Densenet based Robust Face Detection Framework\",\"subtitle\":\"CVF\",\"date\":\"October 28, 2019\",\"description\":\"Face Detection on the WIDER FACE Dataset.\"},{\"title\":\"Kinship Verification using Deep Siamese Convolutional Neural Network\",\"subtitle\":\"IEEE\",\"date\":\"July 11, 2019\"},{\"title\":\"An Adaptive Anaphylaxis Detection and Emergency Response System\",\"subtitle\":\"IEEE\",\"date\":\"June 1, 2019\"},{\"title\":\"Low-cost Brain Controlled Orthotic Exoskeleton Arm for Monoplegic Paralyzed Individuals\",\"subtitle\":\"IEEE\",\"date\":\"May 18, 2018\"},{\"title\":\"Understanding Community Rivalry on Social Media: A Case Study of Two Footballing Giants.\"}]",
    "patents": null,
    "projects": null,
    "honors_and_awards": [
        {
            "title": "Microsoft Research India PhD Awardee",
            "publication": "Microsoft Research India",
            "date": "2024-07-01T00:00:00.000Z",
            "description": "#:~:text=The%20MSR%20India%20PhD%20Award,strong%20research%20community%20in%20India."
        },
        {
            "title": "Prime Minister's Research Fellowship",
            "publication": "-",
            "date": "2021-03-01T00:00:00.000Z",
            "description": null
        },
        {
            "title": "National Talent Search Examination Awardee",
            "publication": "National Council of Educational Research and Training (NCERT)",
            "date": "2011-01-01T00:00:00.000Z",
            "description": "The National Talent Search Examination (NTSE) is one of the most competitive exams in India. NTSE Scholarship is a prestigious scholarship program."
        }
    ]
}