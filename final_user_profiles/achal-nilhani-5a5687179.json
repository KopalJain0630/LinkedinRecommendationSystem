{
    "city": "Patna, Bihar, India",
    "position": "AI & ML |  Speech & Audio Processing | Medical Image Processing | Computer Vision | Video Processing| NLP | LLM | GenAI",
    "experience": [
        {
            "title": "Research Project Assistant ( Remote)",
            "location": "Kolkata, West Bengal, India",
            "description": "• Drones: Highly efficient for accelerated search operations after disaster.• Till today drones rely mainly on visual inputs from cameras, thermal cameras – Very expensive.• Camera embedded drones ineffective in situations like :1. low or almost no visible light condition (which is very likely after disasters).2. in dense fog, smoky weather or in occlusions.3. victims get trapped under debris (a highly probable situation after earthquake, avalanche orlandslide).4. for searching through the canopy of dense forests.• Thermal cameras fail to work in extreme environment (like in wildfire), dense fog, heavy rain conditionsThen what is the alternative? Answer is Listener Drone, a drone capable of listening to and interpreting sounds like we, humans do.The system works as follows:• As the victims scream for help, the embedded hardware will be able to detect and record the audio data.• The computation using the recordings returns the coordinate of victim with respect to the base station.• The rescue team would track the detected location or coordinate of the victim.Further developments:• Swarm of autonomous Listener Drones to accelerate search and rescue after devastating catastrophes.• Uninterrupted communication between drone to drone and drone to ground using 5G cellular network\ntechnology.",
            "description_html": "• Drones: Highly efficient for accelerated search operations after disaster.• Till today drones rely mainly on visual inputs from cameras, thermal cameras – Very expensive.• Camera embedded drones ineffective in situations like :1. low or almost no visible light condition (which is very likely after disasters).2. in dense fog, smoky weather or in occlusions.3. victims get trapped under debris (a highly probable situation after earthquake, avalanche orlandslide).4. for searching through the canopy of dense forests.• Thermal cameras fail to work in extreme environment (like in wildfire), dense fog, heavy rain conditionsThen what is the alternative? Answer is Listener Drone, a drone capable of listening to and interpreting sounds like we, humans do.The system works as follows:• As the victims scream for help, the embedded hardware will be able to detect and record the audio data.• The computation using the recordings returns the coordinate of victim with respect to the base station.• The rescue team would track the detected location or coordinate of the victim.Further developments:• Swarm of autonomous Listener Drones to accelerate search and rescue after devastating catastrophes.• Uninterrupted communication between drone to drone and drone to ground using 5G cellular network technology.",
            "duration": "Feb 2021 Mar 2022 1 year 2 months",
            "start_date": "Feb 2021",
            "end_date": "Mar 2022",
            "duration_short": "1 year 2 months",
            "company": "Department of Telecommunications ( DOT )",
            "company_id": "department-of-telecommunications-dot-",
            "url": "",
            "company_logo_url": ""
        },
        {
            "title": "AI Devloper - Psychoacoustic Music Device",
            "location": "United States",
            "description": "*The 2021 Moog Hackathon*Hosted by Georgia Tech Center for Music Technology and the Georgia Tech School of Music,  the 2021 Moog Hackathon came to life through a virtual format from February 12-21. For it's 7th annual edition, the Moog Hackathon welcomed 12 student teams that accepted the challenge to design and build novel musical instruments using Moog platforms and other software and hardware prototyping tools.",
            "description_html": "*The 2021 Moog Hackathon*Hosted by&nbsp;Georgia Tech Center for Music Technology&nbsp;and the&nbsp;Georgia Tech School of Music,&nbsp; the 2021 Moog Hackathon came to life through a virtual format from February 12-21. For it's 7th annual edition, the Moog Hackathon welcomed&nbsp;12 student teams&nbsp;that accepted the challenge to design and build novel musical instruments using Moog platforms and other software and hardware prototyping tools. <!---->",
            "duration": "Jan 2021 Feb 2021 2 months",
            "start_date": "Jan 2021",
            "end_date": "Feb 2021",
            "duration_short": "2 months",
            "company": "Georgia Institute of Technology",
            "url": "",
            "company_logo_url": ""
        },
        {
            "title": "Technical Lead",
            "description": "",
            "description_html": " <!---->",
            "duration": "Apr 2020 Apr 2020 1 month",
            "start_date": "Apr 2020",
            "end_date": "Apr 2020",
            "duration_short": "1 month",
            "company": "University of California, Berkeley",
            "url": "",
            "company_logo_url": ""
        },
        {
            "title": "Speech Processing",
            "location": "Banglore",
            "description_html": null,
            "duration": "May 2019 Jul 2019 3 months",
            "start_date": "May 2019",
            "end_date": "Jul 2019",
            "duration_short": "3 months",
            "company": "Indian Institute of Science (IISc)",
            "url": "",
            "company_logo_url": ""
        }
    ],
    "education": [
        {
            "title": "Jadavpur University, Kolkata",
            "degree": "B.E",
            "field": "Electronics and Telecommunication Engineering",
            "url": "",
            "start_year": "2017",
            "end_year": "2021",
            "description": null,
            "description_html": null,
            "institute_logo_url": ""
        }
    ],
    "courses": null,
    "certifications": null,
    "current_company_name": "Department of Telecommunications ( DOT )",
    "publications": "[{\"title\":\"A residual network-based deep learning model for the detection of COVID-19 using cough sounds\",\"subtitle\":\"IOP Publishing Ltd\",\"date\":\"April 13, 2022\",\"description\":\"The method proposed in this chapter addresses the task of discrimination of COVID-19 coughs from non-COVID-19 coughs by using a deep learning model fed with the log-Mel spectrum features of the audio signal. Our main contribution to this ongoing research into the audio-based detection of COVID-19 disease is that we have developed a classification mechanism which yields satisfactory results and is of sufficiently low complexity to be suitable for implementation in low-resource devices.\"},{\"title\":\"A novel sound source localization method using a global-best guided cuckoo search algorithm for drone-based search and rescue operations\",\"subtitle\":\"Unmanned Aerial Systems: Theoretical Foundation and Applications\",\"date\":\"January 29, 2021\",\"description\":\"During disaster management, unmanned aerial vehicles play an important role as they are deployed for effective search and rescue operations. Nowadays, personnel from many emergency services like police officers, firefighters, and volunteers in rescue teams take advantage of drones for cost-effective and time-efficient search and rescue operations. All drone-based search operations to date either have used vision-based drones or require direct human assistance along with the drone. During low or almost no visible light conditions, as well as in foggy weather, it becomes nearly impossible for vision-based drones to continue the search operation. Thus, we propose an alternative approach for drone-based search and rescue operations using acoustic source localization. During the search operation, the sound source is the victim, who is screaming for help. The signal emitted by the source will be recorded using an array of microphones embedded in the drone structure. Thus a novel approach is presented to analyze the captured audio signals for accurate source localization. The proposed method deals with the ego noise and wind noise generated by the motion of drone, its motors, propellers, and other stationary structural noise. A global-best guided cuckoo search optimization algorithm is used to estimate the noise components present in an unknown noisy signal. After estimation of noise either temporal subtraction is used in proposed Algorithm 1 or the Wiener filter as in proposed Algorithm 2 to suppress the noise. Afterward, the time difference of arrival-based sound source localization (SSL) is carried out to compute the coordinates of the speech source. The results demonstrated that Algorithms 1 and 2 both can localize the sound sources effectively whereas conventional SSL algorithms failed to produce the correct results. Further, Algorithm 2 outperforms Algorithm 1 in terms of accurate position estimation and signal-to-noise ratio improvement.\"}]",
    "patents": "[{\"title\":\"AN INTELLIGENT COUGH ANDSPEECH SENSING VISUAL MONITORING DEVICE\",\"date_issued\":\"June 24, 2022\",\"patents_id\":\"202031024977\",\"description\":\"The present invention relates to a portable, low power consuming device to detect and locate coughing person(s) in crowded areas and build-up places with gatherings and in parallel detect the disease causing the cough. The present non-contact, fully automatic device is embedded with alarm system to make alert about existence of infected person in indoor or outdoor environment. More specifically, the present invention discloses a non-contact device comprises of array of Acoustic Sensors (M1-M8) and Image Sensor for audio-visual data acquisition and is equipped with a Processing Unit that works as a brain of this intelligent surveillance system. The said Acoustic sensors, distributed in the form of circular array acquire the audio data from surrounding environment whereas the Image Sensor is used for capturing image of the detected coughing person. Acquired cough data is fed through a Multi-layer Fully Connected recurrent Deep Neural Network model where further analysis is processed.\"}]",
    "projects": "[{\"title\":\"5G RAN with Audio Capture Devices.\",\"start_date\":\"Dec 2021\",\"end_date\":\"Jul 2022\",\"description\":\"The O-RAN 5G SA vRAN solution consists of a near-RT RIC, CU-CP, CU-UP and xApp framework components. Implementing 3GPP Control User Plane Separation (CUPS) allows the user and control planes to be fully decoupled. It supports 5G gNB using standards-based DU/RUs from the developing ecosystem of 5G Open RAN\"},{\"title\":\"Microsoft Deep Noise Seperation Challenge 2021\",\"start_date\":\"Sep 2020\",\"end_date\":\"Jan 2021\",\"description\":\"The Deep Noise Suppression (DNS) challenge is designed to foster innovation in the area of noise suppression to achieve superior perceptual speech quality. We recently organized a DNS challenge special session at INTERSPEECH 2020 and ICASSP 2020. We open-sourced training and test datasets for the wideband scenario. We also open-sourced a subjective evaluation framework based on ITU-T standard P.808, which was used to evaluate challenge submissions. Many researchers from academia and industry made significant contributions to push the field forward, yet even the best noise suppressor was far from achieving superior speech quality in challenging scenarios. In this version of the challenge organized at INTERSPEECH 2021, we are expanding both our training and test datasets to accommodate full band scenarios. The two tracks in this challenge will focus on real-time denoising for (i) wide band, and (ii) full band scenarios. We are also making available a reliable non-intrusive objective speech quality metric for wide band called DNSMOS for the participants to use during their development phase.\"},{\"title\":\"DEVELOPMENT OF LOW-COST VENTILATORS FOR PATIENTS DURING COVID-19PANDEMIC\",\"start_date\":\"Apr 2020\",\"end_date\":\"Jun 2020\",\"description\":\"* Selected as Winner Project by UC Berkeley (CEND) and received grant USD 1,000 forventilator prototype development.* Technical Head in a team of 6 membersDesigned a low-cost, easily deployable ventilator system with featuresincluding air pressure, flow, tidal volume, Positive End Expiratory Pressure(PEEP), Fraction of Inspired Oxygen (FIO2) control.\"},{\"title\":\"DRONE: FOR EFFECTIVE SEARCH AND RESCUE OPERATION USINGSOUND SOURCE LOCALIZATION\",\"start_date\":\"Sep 2019\",\"end_date\":\"Feb 2020\",\"description\":\"* A novel optimization based algorithm to eliminate ego noise and wind noisefrom drone embedded microphone array data for accurate sound (speech)localization using angular spectrum methods.* Developed a market-ready prototype with proposed algorithm implemented init. Future plan is to implement this concept for swarm of drones to facilitatewide area coverage in lesser time.* Presently aiming to commercialize the system for the use of first responseteams globally.\"},{\"title\":\"MULTIPLE SENSOR BASED ADVENTITIOUS LUNG SOUND LOCALIZATIONALGORITHMS AND ASSESSMENT USING 3D PRINTED THORACIC PHANTOM.\",\"start_date\":\"May 2019\",\"end_date\":\"Jul 2019\",\"description\":\"* Developed the multichannel acoustic sensor array hardware system forcontinuous and synchronous audio data acquisition from human lungs.* Successfully tested the system by installing on a 3D printed human thoracicphantom.\"},{\"title\":\"THE VIRAL COUGH COP DEVICE (VCC) for covid19.\",\"description\":\"* An intelligent, low-cost (under $135) device to detect cough sounds anddiagnose therespiratory disease causing the cough and simultaneouslyidentify the coughing person(s) usingaudio-visual feedback from multichannelacoustic and visual sensors.* Potential use in indoor environments like Quarantine centers, Office-spaces,Classrooms, Seminar halls, Community Gathering Halls, Hospitals and Clinics.* Received supportive feedback from Indian Council of Medical Research(ICMR). Presently working towards mass-production of the device.\"}]",
    "honors_and_awards": [
        {
            "title": "CuseHack2021",
            "publication": "Syracuse University , USA",
            "date": "2021-03-01T00:00:00.000Z",
            "description": "Moog-Emotion is an intelligent music system that utilizes different psychological aspects of music to accompany us in our every mood. In other words, it is a musical instrument that tunes itself according to the user’s current emotions and can also control their moods through generation of suitable music."
        },
        {
            "title": "Top 30 Project in 5G Hackthon , Department Of Telecommunications, Govt. Of India",
            "publication": "-",
            "date": "2020-11-01T00:00:00.000Z",
            "description": "Jadavpur University at India Mobile Congress 2020 South Asia's Biggest Digital Technology Event. Thanks to the Department of Telecommunications, Govt. of India for nominating us among the Top 30 projects in 5G Hackathon 2020 and inviting us to exhibit project Listener Drone."
        },
        {
            "title": "13th International Rank in IEEE Signal Processing Cup Organised by IEEE Signal Processing Society & ICASSP",
            "publication": "2019",
            "date": "2019-03-01T00:00:00.000Z",
            "description": null
        },
        {
            "title": "Finalist Of XILINX Innovation Challange , IIT Kharagpur",
            "publication": "2018",
            "date": "2018-01-01T00:00:00.000Z",
            "description": null
        },
        {
            "title": "Microsoft Deep Noise Suppression Challange-2021",
            "publication": "18th November 2021",
            "date": null,
            "description": ""
        }
    ]
}